{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer Vision Lab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUvp/SfuxLRxywrUXd9SkR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SayedNadim/TA_computer_vision/blob/main/Computer_Vision_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqVzOayZ7psw"
      },
      "source": [
        "# This is a code cell\n",
        "# If you write your code here and press the \"play\" button, it will compile and run.\n",
        "# Let's start!!"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pzroCXR9KBQ"
      },
      "source": [
        "This is a text block. You can enter your text, explanation, process etc. for reference. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxzaEHpF9aE6",
        "outputId": "b14b03c8-c36f-4887-e5dd-65bf9ab67952"
      },
      "source": [
        "print('Hello world!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ0uxr7X_3k9"
      },
      "source": [
        "# importing numpy for numerical python\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUCfsE88_9Kx"
      },
      "source": [
        "# array operations\n",
        "a = np.array([1,2,3,4])\n",
        "b = np.array([5,6,7,8])\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TomeyeFALhS",
        "outputId": "58b130e1-8412-417e-8e56-a2c661a08dd1"
      },
      "source": [
        "sum = a+b # addition\n",
        "print('Sum: {}'.format(sum))\n",
        "sub = b-a # subtraction\n",
        "print('Sub: {}'.format(sub))\n",
        "mul = a*b # multiplication\n",
        "print('Mul: {}'.format(mul))\n",
        "fdiv = b/a # float Division\n",
        "print('Float Div: {}'.format(fdiv))\n",
        "idiv = b//a # Int Division\n",
        "print('Int Div: {}'.format(idiv))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum: [ 6  8 10 12]\n",
            "Sub: [4 4 4 4]\n",
            "Mul: [ 5 12 21 32]\n",
            "Float Div: [5.         3.         2.33333333 2.        ]\n",
            "Int Div: [5 3 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Nr5VsQtBzXo",
        "outputId": "97bfb276-b08f-48bd-a988-2a7e728b1caf"
      },
      "source": [
        "# Loop\n",
        "for i in range(10):\n",
        "  print(i)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "627nMY3zCfd4",
        "outputId": "6402fa80-a159-4214-c6e0-2f6f69cd849f"
      },
      "source": [
        "# indexing\n",
        "f = np.array([[1,2,3], [4,5,6]]) # 2D array\n",
        "print('array: {}'.format(f))\n",
        "print('0th row, 0th column: {}'.format(f[0,0]))\n",
        "print('1st row, 2nd column: {}'.format(f[1,2]))\n",
        "print('Last row, last column: {}'.format(f[-1,-1]))\n",
        "print('All values of rows, 0th column: {}'.format(f[:,0]))\n",
        "print('All values of 2 nd column: {}'.format(f[:,2]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array: [[1 2 3]\n",
            " [4 5 6]]\n",
            "0th row, 0th column: 1\n",
            "1st row, 2nd column: 6\n",
            "Last row, last column: 6\n",
            "All values of rows, 0th column: [1 4]\n",
            "All values of 2 nd column: [3 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5wnZwpfYwTC",
        "outputId": "61aed399-9e96-43ea-e220-d4291d2f7265"
      },
      "source": [
        "import time\n",
        "\n",
        "d = 5000\n",
        "\n",
        "# using numpy\n",
        "time_np_start = time.time()\n",
        "A = np.random.rand(d,d).astype(np.float32)\n",
        "B = np.random.rand(d,d).astype(np.float32)\n",
        "C = A.dot(B)\n",
        "time_np_end = time.time()\n",
        "print(\"Numpy took {} ms.\".format(time_np_end - time_np_start))\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy took 5.338991641998291 ms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqTBIhRSZ5u-"
      },
      "source": [
        "import torch\n",
        "\n",
        "# using GPU\n",
        "time_gpu_start = time.time()\n",
        "A = torch.rand(d,d).cuda()\n",
        "B = torch.rand(d,d).cuda()\n",
        "C = torch.mm(A, B)\n",
        "time_gpu_end = time.time()\n",
        "print(\"GPU took {} ms.\".format(time_gpu_end - time_gpu_start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpPlDGNUGjqR"
      },
      "source": [
        "# OOP idea\n",
        "# Constructor\n",
        "\n",
        "class Human(object):\n",
        "  def __init__(self, hand, leg, head, eyes):\n",
        "    self.hand = hand\n",
        "    self.leg = leg \n",
        "    self.head = head \n",
        "    self.eyes = eyes\n",
        "  \n",
        "  def forward(self):\n",
        "    identity_string = \"I have {} head, {} eyes, {} hand and {} leg\".format(self.head, self.eyes, self.hand, self.leg)\n",
        "    return identity_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYrz4xSfG_Ee"
      },
      "source": [
        "human_object_0 = Human(hand=2, leg=2, head=1, eyes=2) # initialization\n",
        "human_object_0.forward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgsZkMCVHXO5"
      },
      "source": [
        "human_object_1 = Human(hand=4, leg=4, head=2, eyes=4) # initialization\n",
        "human_object_1.forward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTW0zzrxHocN"
      },
      "source": [
        "# Another constructor\n",
        "\n",
        "class Job(object):\n",
        "  def __init__(self, role, salary):\n",
        "    self.role = role\n",
        "    self.salary = salary \n",
        "  \n",
        "  def forward(self):\n",
        "    job_string = \"I have a {} role and {} salary\".format(str(self.role), self.salary)\n",
        "    return job_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEgA3l-FH180"
      },
      "source": [
        "job_class1 = Job('manager', 5000)\n",
        "job_class1.forward()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJXDjcb5IGSM"
      },
      "source": [
        "job_class2 = Job('boss', 8000)\n",
        "job_class2.forward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIVXk1GKIQel"
      },
      "source": [
        "# Constructor with constructor\n",
        "\n",
        "class Work(object):\n",
        "  def __init__(self):\n",
        "    self.human = Human(hand=2, leg=2, head=1, eyes=2)\n",
        "    self.job = Job('Student', 2000)\n",
        "  \n",
        "  def forward(self):\n",
        "    human_1 = self.human.forward()\n",
        "    job_1 = self.job.forward()\n",
        "    return human_1 + \", \" + job_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GEF3EidIkQN"
      },
      "source": [
        "work_object_0 = Work()\n",
        "work_object_0.forward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_PZyk4JLkZy"
      },
      "source": [
        "# checking GPU properties with PyTorch\n",
        "\n",
        "# importing pytorch\n",
        "import torch \n",
        "\n",
        "# check whether we have GPU or not. If not, we have to change the runtime\n",
        "print(\"Are we using GPU: {}\".format(torch.cuda.is_available())) \n",
        "\n",
        "# if GPU is true, which GPU are we using?\n",
        "print(\"Which GPU are we using: {}\".format(torch.cuda.current_device())) \n",
        "\n",
        "# What are the properties of our current GPU?\n",
        "print(\"What's our GPU's properties: {}\".format(torch.cuda.get_device_properties(0))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3dqc9V5S0wl"
      },
      "source": [
        "# dataset upload - method 2\n",
        "# we will use \"drive\" class from Colab\n",
        "# it will access our gdrive for dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # mounting drive\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z5ojU_uUekB"
      },
      "source": [
        "file_name = '08.cvip_dog_cat_dataset.zip' \n",
        "zip_path = '/content/drive/MyDrive/08.cvip_dog_cat_dataset.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U96uLw0KUo-G"
      },
      "source": [
        "!cp \"{zip_path}\" . # copying content to our current workspace. Don't forget the \".\" at the end.\n",
        "!unzip -q -o \"{file_name}\" # unzipping the file\n",
        "!rm \"{file_name}\" # removing original zip file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL3DUSeeQMnA"
      },
      "source": [
        "train_root = './train/dog'\n",
        "val_root = './val/cat'\n",
        "test_root = './test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHCEE0qzQxz2"
      },
      "source": [
        "import os # for accessing files\n",
        "from matplotlib import pyplot as plt # for image visualization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyooDQjERHqj"
      },
      "source": [
        "train_examples = os.listdir(train_root) # list training examples\n",
        "val_examples = os.listdir(val_root) # list validation examples\n",
        "test_examples = os.listdir(test_root) # list test examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuWOngdyRaso"
      },
      "source": [
        "print('length of train set: {}'.format(len(train_examples)))\n",
        "print('length of validation set: {}'.format(len(val_examples)))\n",
        "print('length of test set: {}'.format(len(test_examples)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNbvFipGRrek"
      },
      "source": [
        "image = plt.imread(train_root + '/' + train_examples[0]) # reading first image in the training dataset\n",
        "plt.imshow(image) # showing the image using matplotlib\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG-I8wNOcORz"
      },
      "source": [
        "# creating a tensor\n",
        "new_tensor = torch.tensor([[1,2], [3,4]], dtype=torch.float32)\n",
        "new_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0PxixVPdBjz"
      },
      "source": [
        "# creating a int tensor\n",
        "new_tensor_int = torch.tensor([[1,2], [3,4]], dtype=torch.int8)\n",
        "new_tensor_int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aFE7cvydvn3"
      },
      "source": [
        "# empty tensor with no predefined value. Full of garbage values\n",
        "empty_tensor = torch.empty(2,3)\n",
        "empty_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L74xi9fePYc"
      },
      "source": [
        "# tensor with uniform distribution\n",
        "uniform_tensor = torch.empty((2,3), dtype=torch.float32).uniform_(-1,1)\n",
        "uniform_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igEryFgLe0XN"
      },
      "source": [
        "# tensor with random value\n",
        "random_tensor = torch.rand(size=(2,3))\n",
        "random_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAHMjSLAfHaA"
      },
      "source": [
        "# tensor with zero values\n",
        "zeros_tensor = torch.zeros(size=(2,3))\n",
        "zeros_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLVLDbEWfP86"
      },
      "source": [
        "# tensor with one values\n",
        "ones_tensor = torch.ones(size=(2,3))\n",
        "ones_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRRUG0tbfVBc"
      },
      "source": [
        "# creating identity matrix \n",
        "identity_matrix = torch.eye(3)\n",
        "identity_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbcqkcSRirgc"
      },
      "source": [
        "# tensor operations\n",
        "a = torch.rand(4,4)\n",
        "b = torch.rand(4,4)\n",
        "\n",
        "sum = a+b # addition\n",
        "print('Sum: {}'.format(sum))\n",
        "sub = b-a # subtraction\n",
        "print('Sub: {}'.format(sub))\n",
        "mul = a*b # multiplication\n",
        "print('Mul: {}'.format(mul))\n",
        "fdiv = b/a # float Division\n",
        "print('Float Div: {}'.format(fdiv))\n",
        "idiv = b//a # Int Division\n",
        "print('Int Div: {}'.format(idiv))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsEDuL-Cgkcb"
      },
      "source": [
        "# declare a random tensor\n",
        "x = torch.rand(1)\n",
        "x.requires_grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD3A51PghOAo"
      },
      "source": [
        "# declare a random tensor with gradient calculation\n",
        "x = torch.rand(1, requires_grad=True)\n",
        "x.requires_grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZndxh3nhS1y"
      },
      "source": [
        "# basic graph\n",
        "x = torch.rand(1, requires_grad=True)\n",
        "y = 3 * x + 5 \n",
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sserKaSjofpB"
      },
      "source": [
        "from torch import nn # neural network module\n",
        "from torch.nn import functional as F # you can use this or use nn\n",
        "\n",
        "# remember, in torch, data is arranged as\n",
        "# [Batch, Channel, Height, Width]\n",
        "\n",
        "dummy_input = torch.rand(1,3,64,64) \n",
        "# it means, we have a batch of image with\n",
        "# batch size = 1\n",
        "# channel = 3\n",
        "# height = 64\n",
        "# width = 64\n",
        "\n",
        "dummy_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Qo7CYLpS-S"
      },
      "source": [
        "convolution_layer = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "feature_map = convolution_layer(dummy_input)\n",
        "print(\"Output feature map size: \", feature_map.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRHRhdXMs4NC"
      },
      "source": [
        "activation_layer = nn.ReLU()\n",
        "activated_feature_map = activation_layer(feature_map)\n",
        "print(\"Output activated feature map size: \", activated_feature_map.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCV-cmVStJaf"
      },
      "source": [
        "pooling_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "pooled_feature_map = pooling_layer(activated_feature_map)\n",
        "print(\"Output pooled_feature_map size: \", pooled_feature_map.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRKpofDUuje0"
      },
      "source": [
        "# to feed in linear/FC layer, we need to flatten the feature map\n",
        "flattened_feature_map = pooled_feature_map.view(pooled_feature_map.size(0), -1)\n",
        "# it means, the size will be [Batch, Channel * Height * Width] = [1, 32*32*32] \n",
        "# instead of [Batch, Channel, Height, Width]\n",
        "print('Flattened shape: ', flattened_feature_map.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXxsKlEjvYR2"
      },
      "source": [
        "fc_layer = nn.Linear(32*32*32, 2)\n",
        "class_feature = fc_layer(flattened_feature_map)\n",
        "print(\"Output class feature size: \", class_feature.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoYdi91Qx47Q"
      },
      "source": [
        "# classification layer\n",
        "output_classes = torch.sigmoid(class_feature)\n",
        "print(\"Class probabilities: \", output_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAErDl3wxtSA"
      },
      "source": [
        "# let's make a network using OOP + PyTorch\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # declaring conv layers\n",
        "    self.conv_layer_1 = nn.Conv2d(in_channels=3, out_channels=32,kernel_size=3,stride=1, padding=1)\n",
        "    self.relu_1 = nn.ReLU()\n",
        "    self.max_pool_1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv_layer_2 = nn.Conv2d(in_channels=32, out_channels=64,kernel_size=3,stride=1, padding=1)\n",
        "    self.relu_2 = nn.ReLU()\n",
        "    self.max_pool_2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.linear = nn.Linear(64*16*16, 1) # FC layer\n",
        "    self.class_prob = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # calling layer 1\n",
        "    x = self.conv_layer_1(x) # [1,3,64,64] -> [1, 32, 64,64]\n",
        "    x = self.relu_1(x)       # [1,32,64,64] -> [1, 32, 64,64]\n",
        "    x = self.max_pool_1(x)   # [1,32,64,64] -> [1, 32, 32,32]\n",
        "    # calling layer 2\n",
        "    x = self.conv_layer_2(x) # [1,32,32,32] -> [1, 64, 32,32]\n",
        "    x = self.relu_2(x)\n",
        "    x = self.max_pool_2(x)   # [1,64,32,32,] -> [1, 64, 16,16]\n",
        "    # flattening the feature for linear layer\n",
        "    x = x.view(x.size(0), -1)\n",
        "    # calling the linear/ fc layer\n",
        "    x = self.linear(x)\n",
        "    # returning the value\n",
        "    x = self.class_prob(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3vn14MfysN7"
      },
      "source": [
        "neural_network = NeuralNetwork()\n",
        "net_input = torch.rand(1,3,64,64)\n",
        "output = neural_network(net_input)\n",
        "print(\"Class probabilities: \", output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81i7_Gdx0FZc"
      },
      "source": [
        "gt = torch.empty((1,1)).random_(2)\n",
        "print(\"Ground Truth: \", gt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnFRtiO80MHo"
      },
      "source": [
        "loss_function = nn.BCELoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvgUnluu0Yos"
      },
      "source": [
        "loss = loss_function(output, gt)\n",
        "print(\"Loss: \", loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDriA33W1T_w"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wJVmDEJ3sUS"
      },
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from torchvision.transforms import Compose, ToTensor, ToPILImage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvhobYeH5GQL"
      },
      "source": [
        "index_to_name = ['CAT', 'DOG']\n",
        "name_to_index = {\n",
        "    'CAT': 0,\n",
        "    'DOG' : 1\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZsVKvGB5dp4"
      },
      "source": [
        "class CatDogDataset(data.Dataset):\n",
        "  def __init__(self, root_path):\n",
        "    super().__init__\n",
        "\n",
        "    self.root_path = root_path\n",
        "    self.samples = None\n",
        "    self.transforms = Compose([ToTensor()])\n",
        "\n",
        "  def set_mode(self, mode):\n",
        "    if mode == 'training':\n",
        "      cat_dir = os.path.join(self.root_path, 'cat')\n",
        "      dog_dir = os.path.join(self.root_path, 'dog')\n",
        "\n",
        "      cat_samples = [(os.path.join('cat', filename), name_to_index['CAT']) for filename in os.listdir(cat_dir)]\n",
        "      dog_samples = [(os.path.join('dog', filename), name_to_index['DOG']) for filename in os.listdir(dog_dir)]\n",
        "      \n",
        "      self.samples = cat_samples + dog_samples\n",
        "    elif mode == 'validation':\n",
        "      cat_dir = os.path.join(self.root_path, 'cat')\n",
        "      dog_dir = os.path.join(self.root_path, 'dog')\n",
        "\n",
        "      cat_samples = [(os.path.join('cat', filename), name_to_index['CAT']) for filename in os.listdir(cat_dir)]\n",
        "      dog_samples = [(os.path.join('dog', filename), name_to_index['DOG']) for filename in os.listdir(dog_dir)]\n",
        "      \n",
        "      self.samples = cat_samples + dog_samples\n",
        "    \n",
        "    elif mode == 'testing':\n",
        "      self.samples = [(filename, None) for filename in os.listdir(self.root_path)]\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.samples)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    filename, label = self.samples[idx]\n",
        "    img = plt.imread(os.path.join(self.root_path, filename))\n",
        "    img = self.transforms(img)\n",
        "\n",
        "    sample = {\n",
        "        'img': img,\n",
        "        'filename': filename\n",
        "    }\n",
        "    if label is not None:\n",
        "      sample['label'] = label\n",
        "\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc2uiusR7kq4"
      },
      "source": [
        "train_root = './train'\n",
        "test_root = './test'\n",
        "val_root = './val'\n",
        "\n",
        "train_dataset = CatDogDataset(train_root)\n",
        "train_dataset.set_mode('training')\n",
        "\n",
        "test_dataset = CatDogDataset(test_root)\n",
        "test_dataset.set_mode('testing')\n",
        "\n",
        "val_dataset = CatDogDataset(val_root)\n",
        "val_dataset.set_mode('validation')\n",
        "\n",
        "print(\"Train samples #: \", len(train_dataset))\n",
        "print(\"Test samples #: \", len(test_dataset))\n",
        "print(\"Val samples #: \", len(val_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drd_rt-J8s9z"
      },
      "source": [
        "# check a sample\n",
        "\n",
        "sample = train_dataset[0]\n",
        "img = sample['img']\n",
        "label = sample['label']\n",
        "\n",
        "print(\"image shape: \", img.shape, \" label: \", label)\n",
        "plt.imshow(ToPILImage()(img))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eX5yjbeGGw7"
      },
      "source": [
        "# finally, the dataloader\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "val_dataloader = data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# iterable\n",
        "batch = iter(train_dataloader)\n",
        "sample = batch.next()\n",
        "\n",
        "\n",
        "# check \n",
        "img = sample['img']\n",
        "label = sample['label']\n",
        "\n",
        "print(img.shape, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f3zfRWICHuy"
      },
      "source": [
        "import tqdm\n",
        "from torch import optim\n",
        "\n",
        "# step 0: set hyperparameters\n",
        "total_epoch = 20\n",
        "\n",
        "# step 1: network setting\n",
        "net = NeuralNetwork().cuda() # net in GPU\n",
        "\n",
        "# step 2: set loss and weight optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
        "\n",
        "# keep track\n",
        "train_info = []\n",
        "val_info = []\n",
        "\n",
        "# save files\n",
        "save_path = './ClassificationNet'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "output_path = os.path.join(save_path, 'net_version_1.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyVEKYb0DUYc"
      },
      "source": [
        "def train_one_epoch(net, dataloader):\n",
        "  confusion_matrix = [[0,0],[0,0]] # check network's ability to predict\n",
        "  total_loss = 0 # 1 epoch loss\n",
        "  iteration = 0 # step number \n",
        "\n",
        "  net.train() # -> important !!!!!!!!\n",
        "\n",
        "  for sample in tqdm.tqdm(dataloader):\n",
        "    img = sample['img']\n",
        "    label = sample['label']\n",
        "\n",
        "    # send data to gpu\n",
        "    img = img.float().cuda()\n",
        "    label = label.float().cuda()\n",
        "\n",
        "    # make optimizer zero\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = net(img).squeeze(1) # [Batch, 1] -> [Batch]\n",
        "\n",
        "    # loss calculation\n",
        "    loss = criterion(output, label)\n",
        "    loss.backward()\n",
        "    optimizer.step() # optimizing :)\n",
        "\n",
        "    # total loss calculation\n",
        "    total_loss += loss.detach() # detaching from graph\n",
        "    iteration +=1\n",
        "\n",
        "    # confusion matrix\n",
        "    for i in range(len(label)):\n",
        "      real_class = int(label[i])\n",
        "      pred_class = int(output[i]>0.5) # sigmoid outputs from 0.5\n",
        "      confusion_matrix[real_class][pred_class] +=1\n",
        "  positive = confusion_matrix[0][0] + confusion_matrix[1][1]\n",
        "  negative = confusion_matrix[1][0] + confusion_matrix[0][1]\n",
        "  accuracy = positive/(positive+negative)\n",
        "  total_loss /= iteration\n",
        "\n",
        "  return accuracy, total_loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vGz33Z4SLvb"
      },
      "source": [
        "def validation_one_epoch(net, dataloader):\n",
        "  confusion_matrix = [[0,0],[0,0]] # check network's ability to predict\n",
        "  total_loss = 0 # 1 epoch loss\n",
        "  iteration = 0 # step number \n",
        "\n",
        "  net.eval() # -> important !!!!!!!!\n",
        "\n",
        "  for sample in tqdm.tqdm(dataloader):\n",
        "    img = sample['img']\n",
        "    label = sample['label']\n",
        "\n",
        "    # send data to gpu\n",
        "    img = img.float().cuda()\n",
        "    label = label.float().cuda()\n",
        "\n",
        "    # we will not use optimizer\n",
        "    # optimizer.zero_grad()\n",
        "\n",
        "    output = net(img).squeeze(1) # [Batch, 1] -> [Batch]\n",
        "\n",
        "    # loss calculation\n",
        "    loss = criterion(output, label)\n",
        "    # loss.backward()\n",
        "    # optimizer.step() # we will not optimize\n",
        "\n",
        "    # total loss calculation\n",
        "    total_loss += loss.detach() # detaching from graph\n",
        "    iteration +=1\n",
        "\n",
        "    # confusion matrix\n",
        "    for i in range(len(label)):\n",
        "      real_class = int(label[i])\n",
        "      pred_class = int(output[i]>0.5) # sigmoid outputs from 0.5\n",
        "      confusion_matrix[real_class][pred_class] +=1\n",
        "  positive = confusion_matrix[0][0] + confusion_matrix[1][1]\n",
        "  negative = confusion_matrix[1][0] + confusion_matrix[0][1]\n",
        "  accuracy = positive/(positive+negative)\n",
        "  total_loss /= iteration\n",
        "\n",
        "  return accuracy, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNIYFjsBFny2"
      },
      "source": [
        "# let's train the model\n",
        "best_accuracy = 0\n",
        "for epoch in range(total_epoch):\n",
        "  accuracy, loss = train_one_epoch(net, train_dataloader)\n",
        "  print(\"Epoch: {}, Accuracy: {}, Loss: {}\".format(epoch, accuracy, loss))\n",
        "  train_info.append({'loss': loss, 'accuracy': accuracy})\n",
        "\n",
        "  with torch.no_grad():\n",
        "    val_accuracy, val_loss = validation_one_epoch(net, val_dataloader)\n",
        "    print(\"validation - Epoch: {}, Accuracy: {}, Loss: {}\".format(epoch, val_accuracy, val_loss))\n",
        "    val_info.append({'loss': val_loss, 'accuracy': val_accuracy})\n",
        "\n",
        "  ## saving the model\n",
        "  if best_accuracy < val_accuracy:\n",
        "    best_accuracy = val_accuracy\n",
        "\n",
        "  torch.save({\n",
        "      'name': \"classification_net_verison_0\",\n",
        "      'accuracy': val_accuracy,\n",
        "      'model_weights': net.state_dict()\n",
        "  }, output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHZIqTIhIn99"
      },
      "source": [
        "def test_one_epoch(net, dataloader):\n",
        "  net.eval() # -> important !!\n",
        "\n",
        "  results = []\n",
        "\n",
        "  for sample in tqdm.tqdm(dataloader):\n",
        "\n",
        "    img = sample['img']\n",
        "    filename = sample['filename']\n",
        "\n",
        "    img = img.float().cuda()\n",
        "    \n",
        "    output = net(img).squeeze(1)\n",
        "\n",
        "    for i in range(len(output)):\n",
        "      results.append('{} {}\\n'.format(filename[i], index_to_name[int(output[i]>0.5)]))\n",
        "  results = sorted(results)\n",
        "  return results\n",
        "\n",
        "\n",
        "results_path = './output.txt'\n",
        "res = test_one_epoch(net, test_dataloader)\n",
        "with open(results_path, 'w') as f:\n",
        "  f.writelines(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_ncCragKRyl"
      },
      "source": [
        "label_path = 'label.txt'\n",
        "output_path = 'output.txt'\n",
        "\n",
        "positive_number = 0\n",
        "total_number = 0\n",
        "\n",
        "with open(label_path, 'r') as f1, open(output_path, 'r') as f2:\n",
        "  gt_list = f1.readlines()\n",
        "  pred_list = f2.readlines()\n",
        "  for gt, pred in zip(gt_list, pred_list):\n",
        "    if gt == pred:\n",
        "      positive_number +=1\n",
        "    total_number +=1\n",
        "print(\"Test accuracy: {}\".format(positive_number/total_number))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmMvMkUIYG6V"
      },
      "source": [
        "# analysis\n",
        "\n",
        "print(len([info['accuracy'] for info in train_info]))\n",
        "print(len([info['accuracy'] for info in val_info]))\n",
        "\n",
        "epoch_axis = np.arange(0, total_epoch)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(epoch_axis, [info['accuracy'] for info in train_info], epoch_axis, [info['accuracy'] for info in val_info], 'r-')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.title('Loss')\n",
        "plt.plot(epoch_axis, [info['loss'] for info in train_info], epoch_axis, [info['loss'] for info in val_info], 'r-')\n",
        "plt.legend(['Train', 'Validation'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}